version: '3.4'

services:
  sparkmaster:
    image: 'dariopad/spark:${STACK_BRANCH}'
    container_name: sparkmaster
    hostname: sparkmaster
    restart: unless-stopped
    ports:
      - '8099:8080'
    networks:
      - iotnet
    environment:
      SPARK_MODE: master
      SPARK_RPC_AUTHENTICATION_ENABLED: "no"
      SPARK_RPC_AUTHENTICATION_SECRET: "no"
      SPARK_RPC_ENCRYPTION_ENABLED: "no"
      SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED: "no"
      SPARK_MASTER_URL: "spark://sparkmaster:7077"
      SPARK_HIVE_EVENTLOG_ENABLED: "true"
      SPARK_HIVE_HDFS_EVENTLOG_DIR: "hdfs://namenode:9000/sparklogs"
      SPARK_HIVE_JDBC: "jdbc:hive2://hive-metastore:10000"
      SPARK_HIVE_WAREHOUSE_STAGING_DIR: "hfds://namenode:9000/hadoop/dfs/data"
      SPARK_HIVE_THRIFT_SERVER: "thrift://hive-metastore:9083"
      SPARK_HIVE_CREDENTIALS_ENABLED: "false"
      SPARK_HIVE_PRINCIPAL: "hiveusr/hivepwd@hive-metastore"
      SPARK_SSL_ENABLED: "no"
      # SPARK_SSL_KEY_PASSWORD:
      # SPARK_SSL_KEYSTORE_FILE: /opt/bitnami/spark/conf/certs/spark-keystore.jks
      # SPARK_SSL_KEYSTORE_PASSWORD:
      # SPARK_SSL_TRUSTSTORE_PASSWORD:
      # SPARK_SSL_TRUSTSTORE_FILE: /opt/bitnami/spark/conf/certs/spark-truststore.jks
      # SPARK_SSL_NEED_CLIENT_AUTH: "no"
      # SPARK_SSL_PROTOCOL: TLSv1.2
      SPARK_DAEMON_USER: "spark"
      SPARK_DAEMON_GROUP: "spark"      
    volumes:
      # - sparkm_data:/opt/bitnami/spark
      - ../data/spark/jobs:/opt/bitnami/spark/app # Spark scripts folder (Must be the same path in airflow and Spark Cluster)
      - ../data/spark/resources:/opt/bitnami/spark/resources #Resources folder (Must be the same path in airflow and Spark Cluster)      

  sparkworker-1:
    image: 'dariopad/spark:${STACK_BRANCH}'
    container_name: sparkworker-1
    hostname: sparkworker-1
    restart: unless-stopped
    networks:
      - iotnet
    environment:
      SPARK_MODE: worker
      SPARK_MASTER_URL: spark://sparkmaster:7077
      SPARK_WORKER_MEMORY: 1G
      SPARK_WORKER_CORES: 1
      SPARK_RPC_AUTHENTICATION_ENABLED: "no"
      SPARK_RPC_AUTHENTICATION_SECRET: "no"
      SPARK_RPC_ENCRYPTION_ENABLED: "no"
      SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED: "no"
      SPARK_HIVE_EVENTLOG_ENABLED: "true"
      SPARK_HIVE_HDFS_EVENTLOG_DIR: "hdfs://namenode:9000/sparklogs"
      SPARK_HIVE_JDBC: "jdbc:hive2://hive-metastore:10000"
      SPARK_HIVE_WAREHOUSE_STAGING_DIR: "hfds://namenode:9000/hadoop/dfs/data"
      SPARK_HIVE_THRIFT_SERVER: "thrift://hive-metastore:9083"
      SPARK_HIVE_CREDENTIALS_ENABLED: "false"
      SPARK_HIVE_PRINCIPAL: "hiveusr/hivepwd@hive-metastore"
      SPARK_SSL_ENABLED: "no"
      # SPARK_SSL_KEY_PASSWORD:
      # SPARK_SSL_KEYSTORE_FILE: /opt/bitnami/spark/conf/certs/spark-keystore.jks
      # SPARK_SSL_KEYSTORE_PASSWORD:
      # SPARK_SSL_TRUSTSTORE_PASSWORD:
      # SPARK_SSL_TRUSTSTORE_FILE: /opt/bitnami/spark/conf/certs/spark-truststore.jks
      # SPARK_SSL_NEED_CLIENT_AUTH: "no"
      # SPARK_SSL_PROTOCOL: TLSv1.2
      SPARK_DAEMON_USER: "spark"
      SPARK_DAEMON_GROUP: "spark"      
    volumes:
      - ../data/spark/jobs:/opt/bitnami/spark/app # Spark scripts folder (Must be the same path in airflow and Spark Cluster)
      - ../data/spark/resources:/opt/bitnami/spark/resources #Resources folder (Must be the same path in airflow and Spark Cluster)      
    depends_on:
      - sparkmaster

  sparkworker-2:
    image: 'dariopad/spark:${STACK_BRANCH}'
    container_name: sparkworker-2
    hostname: sparkworker-2
    restart: unless-stopped
    networks:
      - iotnet
    environment:
      SPARK_MODE: worker
      SPARK_MASTER_URL: spark://sparkmaster:7077
      SPARK_WORKER_MEMORY: 1G
      SPARK_WORKER_CORES: 1
      SPARK_RPC_AUTHENTICATION_ENABLED: "no"
      SPARK_RPC_AUTHENTICATION_SECRET: "no"
      SPARK_RPC_ENCRYPTION_ENABLED: "no"
      SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED: "no"
      SPARK_HIVE_EVENTLOG_ENABLED: "true"
      SPARK_HIVE_HDFS_EVENTLOG_DIR: "hdfs://namenode:9000/sparklogs"
      SPARK_HIVE_JDBC: "jdbc:hive2://hive-metastore:10000"
      SPARK_HIVE_WAREHOUSE_STAGING_DIR: "hfds://namenode:9000/hadoop/dfs/data"
      SPARK_HIVE_THRIFT_SERVER: "thrift://hive-metastore:9083"
      SPARK_HIVE_CREDENTIALS_ENABLED: "false"
      SPARK_HIVE_PRINCIPAL: "hiveusr/hivepwd@hive-metastore"
      SPARK_SSL_ENABLED: "no"
      # SPARK_SSL_KEY_PASSWORD:
      # SPARK_SSL_KEYSTORE_FILE: /opt/bitnami/spark/conf/certs/spark-keystore.jks
      # SPARK_SSL_KEYSTORE_PASSWORD:
      # SPARK_SSL_TRUSTSTORE_PASSWORD:
      # SPARK_SSL_TRUSTSTORE_FILE: /opt/bitnami/spark/conf/certs/spark-truststore.jks
      # SPARK_SSL_NEED_CLIENT_AUTH: "no"
      # SPARK_SSL_PROTOCOL: TLSv1.2
      SPARK_DAEMON_USER: "spark"
      SPARK_DAEMON_GROUP: "spark"      
    volumes:
      # - sparkw_data:/opt/bitnami/spark
      - ../data/spark/jobs:/opt/bitnami/spark/app # Spark scripts folder (Must be the same path in airflow and Spark Cluster)
      - ../data/spark/resources:/opt/bitnami/spark/resources #Resources folder (Must be the same path in airflow and Spark Cluster)      
    depends_on:
      - sparkmaster

  jupyter-spark:
    image: 'dariopad/jupyter-spark:${STACK_BRANCH}'
    container_name: jupyter
    hostname: jupyter
    restart: unless-stopped
    networks:
        - iotnet
    ports:
      - "8888:8888"
      - "4040-4080:4040-4080"
    volumes:
      - ../data/jupyter/notebooks:/opt/jupyter/notebooks/
      - ../data/spark/resources/data:/opt/jupyter/data/
      - ../data/spark/resources/jars:/opt/jupyter/jars/
    depends_on:
      # - airflow
      - sparkmaster
      - sparkworker-1
      - sparkworker-2

networks:
  iotnet:
    external: true
    name: ${DOCKER_NETWORK:-iot_net}