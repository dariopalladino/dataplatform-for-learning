version: '3.4'

services:
  zookeeper1:
    image: 'bitnami/zookeeper:latest'
    container_name: zookeeper1
    hostname: zookeeper1
    restart: unless-stopped
    networks:
      - iotnet
    volumes:
      - zk1_data:/bitnami/zookeeper
    environment:
      - ZOO_MY_ID=1
      - ZOO_SERVER_ID=1
      - ZOO_SERVERS=0.0.0.0:2888:3888,zookeeper2:2888:3888,zookeeper3:2888:3888
      - ZOO_PORT_NUMBER=2181
      - ZOO_TICK_TIME=2000
      - ZOO_INIT_LIMIT=10
      - ZOO_SYNC_LIMIT=5
      - ZOO_MAX_CLIENT_CNXNS=60
      - ZOO_HEAP_SIZE=1024
      - ZOO_AUTOPURGE_PURGEINTERVAL=72
      - ZOO_AUTOPURGE_SNAPRETAINCOUNT=2
      - ALLOW_ANONYMOUS_LOGIN=yes

  zookeeper2:
    image: 'bitnami/zookeeper:latest'
    container_name: zookeeper2
    hostname: zookeeper2
    restart: unless-stopped
    networks:
      - iotnet
    volumes:
      - zk2_data:/bitnami/zookeeper
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes
      - ZOO_MY_ID=2
      - ZOO_SERVER_ID=2
      - ZOO_SERVERS=zookeeper1:2888:3888,0.0.0.0:2888:3888,zookeeper3:2888:3888
      - ZOO_PORT_NUMBER=2181
      - ZOO_TICK_TIME=2000
      - ZOO_INIT_LIMIT=10
      - ZOO_SYNC_LIMIT=5
      - ZOO_MAX_CLIENT_CNXNS=60
      - ZOO_HEAP_SIZE=1024
      - ZOO_AUTOPURGE_PURGEINTERVAL=72
      - ZOO_AUTOPURGE_SNAPRETAINCOUNT=2

  zookeeper3:
    image: 'bitnami/zookeeper:latest'
    container_name: zookeeper3
    hostname: zookeeper3
    networks:
      - iotnet
    volumes:
      - zk3_data:/bitnami/zookeeper
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes
      - ZOO_MY_ID=3
      - ZOO_SERVER_ID=3
      - ZOO_SERVERS=zookeeper1:2888:3888,zookeeper2:2888:3888,0.0.0.0:2888:3888
      - ZOO_PORT_NUMBER=2181
      - ZOO_TICK_TIME=2000
      - ZOO_INIT_LIMIT=10
      - ZOO_SYNC_LIMIT=5
      - ZOO_MAX_CLIENT_CNXNS=60
      - ZOO_HEAP_SIZE=1024
      - ZOO_AUTOPURGE_PURGEINTERVAL=72
      - ZOO_AUTOPURGE_SNAPRETAINCOUNT=2

  kafka-1:
    image: 'bitnami/kafka:latest'
    container_name: kafka-1
    hostname: kafka-1
    restart: unless-stopped
    networks:
      - iotnet
    ports:
      - '19093:19093'
    environment:
      - KAFKA_CFG_BROKER_ID=1
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper1:2181,zookeeper2:2181,zookeeper3:2181
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      - KAFKA_CFG_LISTENERS=INTERNAL://:9092,EXTERNAL://:19093
      - KAFKA_CFG_ADVERTISED_LISTENERS=INTERNAL://kafka-1:9092,EXTERNAL://localhost:19093
      - KAFKA_INTER_BROKER_LISTENER_NAME=INTERNAL
      - KAFKA_CFG_NUM_PARTITIONS=2
      - KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE=false
      - KAFKA_CFG_DEFAULT_REPLICATION_FACTOR=2
      - KAFKA_CFG_OFFSETS_TOPIC_REPLICATION_FACTOR=2
      - KAFKA_CFG_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=2
      - KAFKA_HEAP_OPTS=-Xmx1024m -Xms1024m
    volumes:
      - kafka1_data:/bitnami/kafka
    depends_on:
      - zookeeper1
      - zookeeper2
      - zookeeper3

  kafka-2:
    image: 'bitnami/kafka:latest'
    container_name: kafka-2
    hostname: kafka-2
    restart: unless-stopped
    networks:
      - iotnet
    ports:
      - '29093:29093'
    environment:
      - KAFKA_CFG_BROKER_ID=2
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper1:2181,zookeeper2:2181,zookeeper3:2181
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      - KAFKA_CFG_LISTENERS=INTERNAL://:9092,EXTERNAL://:29093
      - KAFKA_CFG_ADVERTISED_LISTENERS=INTERNAL://kafka-2:9092,EXTERNAL://localhost:29093
      - KAFKA_INTER_BROKER_LISTENER_NAME=INTERNAL
      - KAFKA_CFG_NUM_PARTITIONS=2
      - KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE=false
      - KAFKA_CFG_DEFAULT_REPLICATION_FACTOR=2
      - KAFKA_CFG_OFFSETS_TOPIC_REPLICATION_FACTOR=2
      - KAFKA_CFG_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=2
      - KAFKA_HEAP_OPTS=-Xmx1024m -Xms1024m
    volumes:
      - kafka2_data:/bitnami/kafka
    depends_on:
      - zookeeper1
      - zookeeper2
      - zookeeper3


  kafka-3:
    image: 'bitnami/kafka:latest'
    container_name: kafka-3
    hostname: kafka-3
    restart: unless-stopped
    networks:
      - iotnet
    ports:
      - '39093:39093'
    environment:
      - KAFKA_CFG_BROKER_ID=3
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper1:2181,zookeeper2:2181,zookeeper3:2181
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      - KAFKA_CFG_LISTENERS=INTERNAL://:9092,EXTERNAL://:39093
      - KAFKA_CFG_ADVERTISED_LISTENERS=INTERNAL://kafka-3:9092,EXTERNAL://localhost:39093
      # - KAFKA_CFG_LISTENERS=INTERNAL://0.0.0.0:9092,EXTERNAL://0.0.0.0:9093
      # - KAFKA_CFG_ADVERTISED_LISTENERS=INTERNAL://:9092,EXTERNAL://kafka-3:9093
      - KAFKA_INTER_BROKER_LISTENER_NAME=INTERNAL
      - KAFKA_CFG_NUM_PARTITIONS=2
      - KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE=false
      - KAFKA_CFG_DEFAULT_REPLICATION_FACTOR=2
      - KAFKA_CFG_OFFSETS_TOPIC_REPLICATION_FACTOR=2
      - KAFKA_CFG_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=2
      - KAFKA_HEAP_OPTS=-Xmx1024m -Xms1024m
    volumes:
      - kafka3_data:/bitnami/kafka
    depends_on:
      - zookeeper1
      - zookeeper2
      - zookeeper3

  sparkmaster:
    image: 'dariopad/spark:3.2.0-snapshot'
    container_name: sparkmaster
    hostname: sparkmaster
    restart: unless-stopped
    ports:
      - '8099:8080'
    networks:
      - iotnet
    environment:
      SPARK_MODE: master
      SPARK_RPC_AUTHENTICATION_ENABLED: "no"
      SPARK_RPC_AUTHENTICATION_SECRET: "no"
      SPARK_RPC_ENCRYPTION_ENABLED: "no"
      SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED: "no"
      SPARK_SSL_ENABLED: "no"
      # SPARK_SSL_KEY_PASSWORD:
      # SPARK_SSL_KEYSTORE_FILE: /opt/bitnami/spark/conf/certs/spark-keystore.jks
      # SPARK_SSL_KEYSTORE_PASSWORD:
      # SPARK_SSL_TRUSTSTORE_PASSWORD:
      # SPARK_SSL_TRUSTSTORE_FILE: /opt/bitnami/spark/conf/certs/spark-truststore.jks
      # SPARK_SSL_NEED_CLIENT_AUTH: "no"
      # SPARK_SSL_PROTOCOL: TLSv1.2
      # SPARK_DAEMON_USER: "spark"
      # SPARK_DAEMON_GROUP: "spark"      
    volumes:
      # - sparkm_data:/opt/bitnami/spark
      - ./data/spark/jobs:/opt/bitnami/spark/app # Spark scripts folder (Must be the same path in airflow and Spark Cluster)
      - ./data/spark/resources:/opt/bitnami/spark/resources #Resources folder (Must be the same path in airflow and Spark Cluster)      
    depends_on:
      - kafka-1
      - kafka-2
      - kafka-3

  sparkworker-1:
    image: 'dariopad/spark:3.2.0-snapshot'
    container_name: sparkworker-1
    hostname: sparkworker-1
    restart: unless-stopped
    networks:
      - iotnet
    environment:
      SPARK_MODE: worker
      SPARK_MASTER_URL: spark://sparkmaster:7077
      SPARK_WORKER_MEMORY: 1G
      SPARK_WORKER_CORES: 1
      SPARK_RPC_AUTHENTICATION_ENABLED: "no"
      SPARK_RPC_AUTHENTICATION_SECRET: "no"
      SPARK_RPC_ENCRYPTION_ENABLED: "no"
      SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED: "no"
      SPARK_SSL_ENABLED: "no"
      # SPARK_SSL_KEY_PASSWORD:
      # SPARK_SSL_KEYSTORE_FILE: /opt/bitnami/spark/conf/certs/spark-keystore.jks
      # SPARK_SSL_KEYSTORE_PASSWORD:
      # SPARK_SSL_TRUSTSTORE_PASSWORD:
      # SPARK_SSL_TRUSTSTORE_FILE: /opt/bitnami/spark/conf/certs/spark-truststore.jks
      # SPARK_SSL_NEED_CLIENT_AUTH: "no"
      # SPARK_SSL_PROTOCOL: TLSv1.2
      # SPARK_DAEMON_USER: "spark"
      # SPARK_DAEMON_GROUP: "spark"      
    volumes:
      # - sparkw_data:/opt/bitnami/spark
      - ./data/spark/jobs:/opt/bitnami/spark/app # Spark scripts folder (Must be the same path in airflow and Spark Cluster)
      - ./data/spark/resources:/opt/bitnami/spark/resources #Resources folder (Must be the same path in airflow and Spark Cluster)      
    depends_on:
      - kafka-1
      - kafka-2
      - kafka-3

  sparkworker-2:
    image: 'dariopad/spark:3.2.0-snapshot'
    container_name: sparkworker-2
    hostname: sparkworker-2
    restart: unless-stopped
    networks:
      - iotnet
    environment:
      SPARK_MODE: worker
      SPARK_MASTER_URL: spark://sparkmaster:7077
      SPARK_WORKER_MEMORY: 1G
      SPARK_WORKER_CORES: 1
      SPARK_RPC_AUTHENTICATION_ENABLED: "no"
      SPARK_RPC_AUTHENTICATION_SECRET: "no"
      SPARK_RPC_ENCRYPTION_ENABLED: "no"
      SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED: "no"
      SPARK_SSL_ENABLED: "no"
      # SPARK_SSL_KEY_PASSWORD:
      # SPARK_SSL_KEYSTORE_FILE: /opt/bitnami/spark/conf/certs/spark-keystore.jks
      # SPARK_SSL_KEYSTORE_PASSWORD:
      # SPARK_SSL_TRUSTSTORE_PASSWORD:
      # SPARK_SSL_TRUSTSTORE_FILE: /opt/bitnami/spark/conf/certs/spark-truststore.jks
      # SPARK_SSL_NEED_CLIENT_AUTH: "no"
      # SPARK_SSL_PROTOCOL: TLSv1.2
      # SPARK_DAEMON_USER: "spark"
      # SPARK_DAEMON_GROUP: "spark"      
    volumes:
      # - sparkw_data:/opt/bitnami/spark
      - ./data/spark/jobs:/opt/bitnami/spark/app # Spark scripts folder (Must be the same path in airflow and Spark Cluster)
      - ./data/spark/resources:/opt/bitnami/spark/resources #Resources folder (Must be the same path in airflow and Spark Cluster)      
    depends_on:
      - kafka-1
      - kafka-2
      - kafka-3

  schema-registry:
    image: confluentinc/cp-schema-registry:7.0.0
    hostname: schema-registry
    container_name: schema-registry
    restart: unless-stopped
    depends_on:
      - kafka-1
      - kafka-2
      - kafka-3
    networks: 
      - iotnet
    ports:
      - "8091:8081"
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: 'kafka-1:9092,kafka-2:9092,kafka-3:9092'
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8091


  kafka-rest-proxy:
    image: confluentinc/cp-kafka-rest:7.0.0
    container_name: kafka-rest-proxy
    restart: unless-stopped
    depends_on:
      - kafka-1
      - kafka-2
      - kafka-3
      - schema-registry
    networks: 
      - iotnet
    ports:
      - 8092:8082
    hostname: rest-proxy
    environment:
      KAFKA_REST_HOST_NAME: kafka-rest-proxy
      KAFKA_REST_BOOTSTRAP_SERVERS: 'kafka-1:9092,kafka-2:9092,kafka-3:9092'
      KAFKA_REST_LISTENERS: "http://0.0.0.0:8092"
      KAFKA_REST_SCHEMA_REGISTRY_URL: 'http://schema-registry:8091'

  kafka-ui:
    image: 'obsidiandynamics/kafdrop'
    container_name: 'kafka-ui'
    restart: unless-stopped
    environment:
      - KAFKA_BROKERCONNECT=kafka-1:9092,kafka-2:9092,kafka-3:9092
      - SERVER_PORT=8080
    networks:
      - iotnet
    ports:
      - "8085:8080"
    depends_on:
      - kafka-1
      - kafka-2
      - kafka-3
      - zookeeper1
      - zookeeper2

  elasticsearch:
    image: elasticsearch:7.7.0
    container_name: elasticsearch
    hostname: elasticsearch
    restart: unless-stopped
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=true
      - xpack.security.authc.username=elastic
      - ELASTIC_PASSWORD=$ELASTIC_PASSWORD
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch
    ports:
      - "9200:9200"
      - "9300:9300"
    networks:
      - iotnet
    depends_on:
      - kafka-1
      - kafka-2
      - kafka-3
      - zookeeper1
      - zookeeper2
      - zookeeper3
  
  kibana:
    image: kibana:7.7.0
    container_name: kibana
    hostname: kibana
    restart: unless-stopped
    environment:
      - ELASTICSEARCH_USERNAME=elastic
      - ELASTICSEARCH_PASSWORD=$ELASTIC_PASSWORD
      - XPACK_ENCRYPTEDSAVEDOBJECTS_ENCRYPTIONKEY=962da75616a8fec5adcdcf7151edcb6531ac6ffaddfc97250fb65bfefc056069
      - XPACK_INGESTMANAGER_FLEET_TLSCHECKDISABLED=true    
    volumes:
      - kibana_data:/usr/share/kibana
    ports:
      - "5601:5601"
    links:
      - elasticsearch
    depends_on:
      - elasticsearch
    networks:
      - iotnet
  
  jupyter-spark:
    image: dariopad/jupyter-pyspark:spark-3.2.0-snapshot
    container_name: jupyter
    hostname: jupyter
    restart: unless-stopped
    networks:
        - iotnet
    ports:
      - "8888:8888"
      - "4040-4080:4040-4080"
    volumes:
      - ./data/jupyter/notebooks:/opt/jupyter/notebooks/
      - ./data/spark/resources/data:/opt/jupyter/data/
      - ./data/spark/resources/jars:/opt/jupyter/jars/
    depends_on:
      # - airflow
      - sparkmaster
      - sparkworker-1
      - sparkworker-2

  namenode:
    image: dariopad/hadoop-namenode:3.3.1-snapshot-1
    container_name: namenode
    restart: unless-stopped
    networks:
      - iotnet
    ports:
      - 9870:9870
      - 9000:9000
    volumes:
      - ../data/hadoop/dfs/namenode:/hadoop/dfs/name
    environment:
      - CLUSTER_NAME=test
    env_file:
      - ./hadoop.env

  datanode:
    image: dariopad/hadoop-datanode:3.3.1-snapshot-1
    container_name: datanode
    restart: unless-stopped
    networks:
      - iotnet
    ports:
      - 9864:9864
    volumes:
      - ../data/hadoop/dfs/datanode:/hadoop/dfs/data
    environment:
      CLUSTER_NAME: "test"
      SERVICE_PRECONDITION: "namenode:9870"
    env_file:
      - ./hadoop.env
  
  resourcemanager:
    image: dariopad/hadoop-resourcemanager:3.3.1-snapshot-1
    container_name: resourcemanager
    restart: unless-stopped
    networks:
      - iotnet
    ports:
      - 8088:8088
    environment:
      CLUSTER_NAME: "test"
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode:9864"
    env_file:
      - ./hadoop.env

  nodemanager:
    image: dariopad/hadoop-nodemanager:3.3.1-snapshot-1
    container_name: nodemanager
    restart: unless-stopped
    networks:
      - iotnet
    # ports:
    #   - 8042:8042
    environment:
      CLUSTER_NAME: "test"
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode:9864 resourcemanager:8088"
    env_file:
      - ./hadoop.env
  
  historyserver:
    image: dariopad/hadoop-historyserver:3.3.1-snapshot-1
    container_name: historyserver
    restart: unless-stopped
    networks:
      - iotnet
    # ports:
    #   - 8188:8188
    environment:
      CLUSTER_NAME: "test"
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode:9864 resourcemanager:8088"
    volumes:
      - ../data/hadoop/yarn/timeline:/hadoop/yarn/timeline
    env_file:
      - ./hadoop.env

  hive-server:
    image: dariopad/hive:3.3.1-snapshot-1
    container_name: hive-server
    hostname: hive-server
    restart: unless-stopped
    networks:
      - iotnet
    env_file:
      - ./hive/hadoop-hive.env
    environment:
      HIVE_CORE_CONF_javax_jdo_option_ConnectionURL: "jdbc:postgresql://hive-metastore/metastore"
      SERVICE_PRECONDITION: "hive-metastore:9083"
    ports:
      - "10000:10000"

  hive-metastore:
    image: dariopad/hive:3.3.1-snapshot-1
    container_name: hive-metastore
    hostname: hive-metastore
    restart: unless-stopped
    networks:
      - iotnet
    env_file:
      - ./hive/hadoop-hive.env
    command: /opt/hive/bin/hive --service metastore
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode:9864 hivepostgres:5432"
    ports:
      - "9083:9083"

  hive-postgres:
    image: bitnami/postgresql:latest
    container_name: hivepostgres
    hostname: hivepostgres
    restart: unless-stopped
    networks:
      - iotnet
    ports:
      - '5432:5432'
    volumes:
      - 'hivemetastore_data:/bitnami/postgresql'
      - './postgres-metastore/config:/hive'
    environment:
      - POSTGRESQL_INITSCRIPTS_DIR=/hive
      - POSTGRESQL_PASSWORD=hivepwd
      - POSTGRESQL_DATABASE=metastore
      - POSTGRESQL_USERNAME=hiveuser

  
  # # not sure it's gonna work! 2b tested
  # filebeat:
  #   image: filebeat:7.7.0
  #   container_name: filebeat
  #   hostname: filebeat
  #   restart: unless-stopped
  #   # command: filebeat.sh -E ELASTIC_PASSWORD=$ELASTIC_PASSWORD -E ELASTIC_USERNAME=elastic -E HOST="elasticsearch:9200"
  #   command: filebeat.sh -d processors
  #   environment:
  #     - strict.perms=false
  #     - HOST="elasticsearch:9200"
  #     - ELASTIC_USERNAME=elastic
  #     - ELASTIC_PASSWORD=$ELASTIC_PASSWORD
  #   volumes:
  #     - filebeat_data:/usr/share/filebeat    
  #   ports:
  #     - "9000:8000"
  #   links:
  #     - elasticsearch
  #   depends_on:
  #     - elasticsearch
  #   networks:
  #     - iotnet

  # not needed for now
  # logstash:
  #   image: logstash:7.7.0
  #   container_name: logstash
  #   hostname: logstash
  #   restart: unless-stopped
  #   ports:
  #     - "9600:9600"
  #     - "8089:8089"
  #   volumes:
  #     - ./logstash:/usr/share/logstash/pipeline
  #     - logstash_data:/usr/share/logstash/data
  #     - logstash_config:/usr/share/logstash/config
  #   links:
  #     - elasticsearch:elasticsearch
  #   depends_on:
  #     - elasticsearch
  #   networks:
  #     - iotnet        

  # ===> Beta test not yet fully working <====
  # airflow-scheduler:    
  #   image: dariopad/airflow-spark:latest
  #   container_name: airflow-sk
  #   hostname: airflow-sk
  #   restart: unless-stopped
  #   command: scheduler
  #   environment:
  #     - AIRFLOW_CUSTOM_CONFIG=1
  #     - AIRFLOW_FERNET_KEY=Q-sR1UW5LYGIbG9w1XvB1N725-w66AhR_sTb2HjplaM=
  #     - AIRFLOW_SECRET_KEY=016679103c0ee9fb0cc938a7fb994d92b3756bb13357687dfa45ac4e1a60
  #     - AIRFLOW_DATABASE_HOST=postgresql
  #     - AIRFLOW_DATABASE_PORT_NUMBER=5432
  #     - AIRFLOW_DATABASE_NAME=airflow
  #     - AIRFLOW_DATABASE_USERNAME=airflow-user
  #     - AIRFLOW_DATABASE_PASSWORD=bitnami-pwd
  #     - AIRFLOW_EXECUTOR=CeleryExecutor
  #     - AIRFLOW_WEBSERVER_HOST=airflow
  #     # - AIRFLOW_REDIS_HOST=redis://redis:6379/
  #     # - AIRFLOW_DATABASE_PATH=db+postgresql://airflow:airflow@postgres/airflow
  #     - AIRFLOW_REDIS_HOST=redis
  #     - AIRFLOW_REDIS_PORT_NUMBER=6379
  #   volumes:
  #     - airflow_scheduler_data:/bitnami
  #   networks:
  #     - iotnet 
  #   depends_on:
  #     - airflow     

  # airflow-worker:
  #   image: dariopad/airflow-spark:latest
  #   container_name: airflow-wk
  #   hostname: airflow-wk
  #   restart: unless-stopped
  #   command: worker
  #   environment:
  #     - AIRFLOW_CUSTOM_CONFIG=1
  #     - AIRFLOW_FERNET_KEY=Q-sR1UW5LYGIbG9w1XvB1N725-w66AhR_sTb2HjplaM=
  #     - AIRFLOW_SECRET_KEY=016679103c0ee9fb0cc938a7fb994d92b3756bb13357687dfa45ac4e1a60
  #     - AIRFLOW_DATABASE_HOST=postgresql
  #     - AIRFLOW_DATABASE_PORT_NUMBER=5432
  #     - AIRFLOW_DATABASE_NAME=airflow
  #     - AIRFLOW_DATABASE_USERNAME=airflow-user
  #     - AIRFLOW_DATABASE_PASSWORD=bitnami-pwd
  #     - AIRFLOW_EXECUTOR=CeleryExecutor
  #     - AIRFLOW_WEBSERVER_HOST=airflow
  #     # - AIRFLOW_REDIS_HOST=redis://redis:6379/
  #     # - AIRFLOW_DATABASE_PATH=db+postgresql://airflow:airflow@postgres/airflow
  #     - AIRFLOW_REDIS_HOST=redis
  #     - AIRFLOW_REDIS_PORT_NUMBER=6379
  #   volumes:
  #     - airflow_worker_data:/bitnami
  #   networks:
  #     - iotnet      
  #   depends_on:
  #     - airflow

  # airflow:
  #   image: dariopad/airflow-spark:latest
  #   container_name: airflow
  #   hostname: airflow
  #   restart: unless-stopped
  #   command: webserver
  #   environment:
  #     - LOAD_EX=n
  #     - AIRFLOW_CUSTOM_CONFIG=1
  #     - AIRFLOW_FERNET_KEY=Q-sR1UW5LYGIbG9w1XvB1N725-w66AhR_sTb2HjplaM=
  #     - AIRFLOW_SECRET_KEY=016679103c0ee9fb0cc938a7fb994d92b3756bb13357687dfa45ac4e1a60
  #     - AIRFLOW_DATABASE_HOST=postgresql
  #     - AIRFLOW_DATABASE_PORT_NUMBER=5432
  #     - AIRFLOW_DATABASE_NAME=airflow
  #     - AIRFLOW_DATABASE_USERNAME=airflow-user
  #     - AIRFLOW_DATABASE_PASSWORD=bitnami-pwd
  #     - AIRFLOW_EXECUTOR=CeleryExecutor
  #     - AIRFLOW_WEBSERVER_HOST=airflow
  #     # - AIRFLOW_REDIS_HOST=redis://redis:6379/
  #     # - AIRFLOW_DATABASE_PATH=db+postgresql://airflow:airflow@postgres/airflow
  #     - AIRFLOW_REDIS_HOST=redis
  #     - AIRFLOW_REDIS_PORT_NUMBER=6379
  #   ports:
  #     - '8088:8080'
  #   volumes:
  #     # - airflow_data:/bitnami
  #     - ./data/airflow:/bitnami
  #   networks:
  #     - iotnet

  # this instance is for airflow but we can use the same we have from hive metastore
  # postgresql:
  #   image: bitnami/postgresql:latest
  #   container_name: dp-postgresql
  #   hostname: dp-postgresql
  #   restart: unless-stopped
  #   ports:
  #     - '5432:5432'
  #   volumes:
  #     - postgresql_data:/bitnami/postgresql
  #   environment:
  #     - POSTGRESQL_DATABASE=airflow
  #     - POSTGRESQL_USERNAME=airflow-user
  #     - POSTGRESQL_PASSWORD=bitnami-pwd
  #     # ALLOW_EMPTY_PASSWORD is recommended only for development.
  #     - ALLOW_EMPTY_PASSWORD=yes
  #   networks:
  #     - iotnet   

  # just needed for airflow
  redis:
    image: redis:alpine
    container_name: dp-redis
    hostname: dp-redis
    restart: unless-stopped
    ports:
      - 6379:6379
    volumes:
      - redis_data:/bitnami
    environment:
      # ALLOW_EMPTY_PASSWORD is recommended only for development.
      - ALLOW_EMPTY_PASSWORD=yes
    networks:
      - iotnet      

volumes:  
  zk1_data:
    external:
      name: zk_1_data
  zk2_data:
    external:
      name: zk_2_data
  zk3_data:
    external:
      name: zk_3_data
  kafka1_data:
    external:
      name: kafka1_data
  kafka2_data:
    external:
      name: kafka2_data
  kafka3_data:
    external:
      name: kafka3_data
  sparkm_data:
    external:
      name: spark_m_data
  sparkw_data:
    external:
      name: spark_w_data
  postgresql_data:
    external:
      name: postgresql_data
  redis_data:
    external:
      name: redis_fs_data
  airflow_data:
    external:
      name: airflow_data
  airflow_worker_data:
    external:
      name: airflow_w_data
  airflow_scheduler_data:
    external:
      name: airflow_sk_data
  elasticsearch_data:
    external:
      name: elasticsearch_data
  kibana_data:
    external:
      name: kibana_data
  logstash_data:
    external:
      name: logstash_data
  logstash_config:
    external:
      name: logstash_data2
  hivemetastore_data:
    driver: local      

networks:
  iotnet:
    external: true
    name: iot_net